{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import sys\n",
    "import re\n",
    "import itertools\n",
    "import operator\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from matplotlib import rc,rcParams\n",
    "\n",
    "from gensim.sklearn_api import D2VTransformer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest, chi2\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, ParameterGrid, cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "base = os.getcwd().split('Master-Thesis')[0].replace('\\\\', '/')\n",
    "sys.path.insert(0, base + '/Master-Thesis/research/pre-processing')\n",
    "\n",
    "from pre_processing_functions import *\n",
    "from model_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths for final datset\n",
    "path_dataset = base + '/Master-Thesis/research/pre-processing/final_dataset.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading and defining data\n",
    "df_final= pd.read_pickle(path_dataset)\n",
    "\n",
    "#80/20 split train validation\n",
    "df_final_validation = df_final[:int(0.8*len(df_final))] \n",
    "df_test = df_final[int(0.8*len(df_final)):]             \n",
    "labels_test = df_test.check_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters for gridsearch function\n",
    "scoring - ['f1', 'recall', 'precision']\n",
    "cv = 4\n",
    "refit = 'f1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "N_FEATURES_OPTIONS = [100, 200, 500, 1000, 2500, 5000]\n",
    "C_OPTIONS = [.1, 1, 10, 100, 1000, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline \n",
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), \n",
    "    ('dimred', SelectKBest(chi2)),\n",
    "    ('logistic', LogisticRegression())\n",
    "])\n",
    "\n",
    "parameters = [{\n",
    "    'logistic__C': C_OPTIONS,\n",
    "    'dimred__k': N_FEATURES_OPTIONS \n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Grid search and save results\n",
    "grid_tfidf = GridSearchCV(pipe,parameters,scoring = scoring, cv=cv, refit = refit)\n",
    "grid_tfidf.fit(np.array(texts), np.array(labels))\n",
    "\n",
    "df_idf = gridSearch_to_df(grid_tfidf)\n",
    "df_idf.to_pickle('grid_tfidf.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  TFIDF with categorical and numerical features Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "N_FEATURES_OPTIONS = [100, 200, 500, 1000, 2500, 5000]\n",
    "C_OPTIONS = [.1, 1, 10, 100, 1000, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline \n",
    "model_pipeline_tfidf_f_dimred_tfidfonly = Pipeline(steps=[\n",
    "  (\"features\", FeatureUnion([\n",
    "    (\"numerical_features\", ColumnTransformer([(\"numerical\",Pipeline(steps=[\n",
    "                        (\"impute_stage\", SimpleImputer(missing_values=np.nan, strategy=\"median\",)),\n",
    "                        ('scaler', StandardScaler())]),\n",
    "                        [\"page\", 'unique_words'])])), \n",
    "      \n",
    "    (\"categorical_features\", ColumnTransformer([(\"type\",Pipeline(steps=[\n",
    "                        ('imputer', SimpleImputer(strategy='constant', missing_values=np.nan)),\n",
    "                        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))]),\n",
    "                        [\"uitgifte\", 'splitsing','levering', 'year']),])),\n",
    "      \n",
    "      (\"text_features\",ColumnTransformer([(\"title_vec\",Pipeline(steps=[\n",
    "          (\"tfidf\", TfidfVectorizer()),\n",
    "          ('dimred', SelectKBest(chi2))\n",
    "      ]),\"text_tokenized_joined\")]))])),\n",
    " \n",
    "    \n",
    "  (\"classifiers\", LogisticRegression())\n",
    "])\n",
    "\n",
    "\n",
    "parameters = [{\n",
    "    'classifiers__C': C_OPTIONS,\n",
    "    'features__text_features__title_vec__dimred__k': N_FEATURES_OPTIONS \n",
    "}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Grid search and save results\n",
    "grid_tfidf_features_dimr_tfidfonly = GridSearchCV(model_pipeline_tfidf_f_dimred_tfidfonly,param_grid = parameters, scoring = scoring, cv= cv, refit = refit)\n",
    "grid_tfidf_features_dimr_tfidfonly.fit(df_final_val, df_final_val.check_relevant)\n",
    "\n",
    "df_idf_features = gridSearch_to_df(grid_tfidf_features_dimr_tfidfonly)\n",
    "df_idf_features.to_pickle('grid_tfidf_features.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2vec with stemming and stop word removal Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "C_OPTIONS = [1000]\n",
    "N_SAMPLE_OPTIONS =  [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline\n",
    "piped2v = Pipeline([\n",
    "    ('doc2vec', Doc2VecTransformer(text = 'text_tokenized')), #or Doc2vecTransformer\n",
    "    ('logistic', LogisticRegression())\n",
    "])\n",
    "\n",
    "parameters = [{\n",
    "    'logistic__C': C_OPTIONS,\n",
    "    'doc2vec__sample': N_SAMPLE_OPTIONS \n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Grid search and save results\n",
    "grid_d2v = GridSearchCV(piped2v,param_grid = parameters, scoring = scoring, cv= cv, refit = refit)\n",
    "grid_d2v.fit(df_final_val, df_final_val.check_relevant)\n",
    "df_d2v = gridSearch_to_df(grid_d2v)\n",
    "df_d2v.to_pickle('grid_validation_d2v_stem_stop_sample.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2vec without stemming and stop word removal Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "C_OPTIONS = [1000]\n",
    "N_SAMPLE_OPTIONS =  [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline\n",
    "piped2v = Pipeline([\n",
    "    ('doc2vec', Doc2VecTransformer()), \n",
    "    ('logistic', LogisticRegression())\n",
    "])\n",
    "\n",
    "parameters = [{\n",
    "    'logistic__C': C_OPTIONS,\n",
    "    'doc2vec__sample': N_SAMPLE_OPTIONS \n",
    "}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Grid search and save results\n",
    "grid_d2v = GridSearchCV(piped2v,param_grid = parameters,  scoring = scoring, cv= cv, refit = refit)\n",
    "grid_d2v.fit(df_final_val, df_final_val.check_relevant, )\n",
    "df_d2v = gridSearch_to_df(grid_d2v)\n",
    "df_d2v.to_pickle('grid_validation_d2v_NO_stem_stop_sample.05.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Doc2vec with categorical and numerical features Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "C_OPTIONS = [1000]\n",
    "N_SAMPLE_OPTIONS =  [0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline\n",
    "model_pipeline_d2v_f = Pipeline(steps=[\n",
    "  (\"features\", FeatureUnion([\n",
    "    (\"numerical_features\", ColumnTransformer([(\"numerical\",Pipeline(steps=[\n",
    "                        (\"impute_stage\", SimpleImputer(missing_values=np.nan, strategy=\"median\",)),\n",
    "                        ('scaler', StandardScaler())]),\n",
    "                        [\"page\", 'unique_words'])])), \n",
    "      \n",
    "    (\"categorical_features\", ColumnTransformer([(\"type\",Pipeline(steps=[\n",
    "                        ('imputer', SimpleImputer(strategy='constant', missing_values=np.nan)),\n",
    "                        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))]),\n",
    "                        [\"uitgifte\", 'splitsing','levering', 'year']),])),\n",
    "    \n",
    "    (\"text_features\", Pipeline(steps=[\n",
    "        (\"doc2vec\", Doc2VecTransformer(text = 'text_tokenized')),]),)])),\n",
    "        \n",
    "  (\"classifiers\", LogisticRegression())\n",
    "])\n",
    "\n",
    "parameters = [{\n",
    "    'classifiers__C': C_OPTIONS,\n",
    "    'features__text_features__doc2vec__sample': N_SAMPLE_OPTIONS \n",
    "}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Grid search and save results\n",
    "d2vgrid_features_vec_size = GridSearchCV(model_pipeline_d2v_f,param_grid = parameters, scoring = scoring, cv= cv, refit = refit)\n",
    "d2vgrid_features_vec_size.fit(df_final_val, np.array(df_final_val.check_relevant))\n",
    "d2vgrid_features_vec_size_df = gridSearch_to_df(d2vgrid_features_vec_size)\n",
    "d2vgrid_features_vec_size_df.to_pickle('grid_d2vtt_features_sample.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Ngrams Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "N_FEATURES_OPTIONS = [300, 500, 1000, 2500, 5000]\n",
    "C_OPTIONS = [.1,1,10, 100, 1000, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline\n",
    "pipe_grid_ngram = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range = (3,3), analyzer = 'char')), #or Doc2vecTransformer\n",
    "    ('dimred', SelectKBest(chi2)),\n",
    "    ('logistic', LogisticRegression())\n",
    "])\n",
    "\n",
    "parameters = [{\n",
    "    'logistic__C': C_OPTIONS,\n",
    "    'dimred__k': N_FEATURES_OPTIONS \n",
    "}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Grid search and save results\n",
    "grid_ngram_kbest = GridSearchCV(pipe_grid_ngram,param_grid = parameters, scoring = scoring, cv= cv, refit = refit)\n",
    "grid_ngram_kbest.fit(df_final_val.text_ngrams, labels)\n",
    "df_ngram = gridSearch_to_df(grid_ngram_kbest)\n",
    "df_ngram.to_pickle('grid_ngram.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Ngrams with categorical and numerical features Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "N_FEATURES_OPTIONS = [300, 500, 1000, 2500, 5000]\n",
    "C_OPTIONS = [.1,1,10, 100, 1000, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline\n",
    "model_pipeline_ngram_f_dimred = Pipeline(steps=[\n",
    "  (\"features\", FeatureUnion([\n",
    "    (\"numerical_features\", ColumnTransformer([(\"numerical\",Pipeline(steps=[\n",
    "                        (\"impute_stage\", SimpleImputer(missing_values=np.nan, strategy=\"median\",)),\n",
    "                        ('scaler', StandardScaler())]),\n",
    "                        [\"page\", 'unique_words'])])), \n",
    "      \n",
    "    (\"categorical_features\", ColumnTransformer([(\"type\",Pipeline(steps=[\n",
    "                        ('imputer', SimpleImputer(strategy='constant', missing_values=np.nan)),\n",
    "                        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))]),\n",
    "                        [\"uitgifte\", 'splitsing','levering','year']),])),\n",
    "    \n",
    "      (\"text_features\",ColumnTransformer([(\"title_vec\",Pipeline(steps=[\n",
    "          ('tfidf', TfidfVectorizer(ngram_range = (3,3), analyzer = 'char')),\n",
    "          (\"dimred\", SelectKBest(chi2))])                                          \n",
    "        ,\"text_ngrams\")]))])),\n",
    "    \n",
    "    \n",
    "  (\"classifiers\", LogisticRegression())\n",
    "])\n",
    "\n",
    "\n",
    "parameters = [{\n",
    "    'classifiers__C': C_OPTIONS,\n",
    "    'features__text_features__title_vec__dimred__k': N_FEATURES_OPTIONS \n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Grid search and save results\n",
    "grid_ngram_features_dimr_tfidfonly = GridSearchCV(model_pipeline_ngram_f_dimred,param_grid = parameters, scoring = scoring, cv= cv, refit = refit)\n",
    "grid_ngram_features_dimr_tfidfonly.fit(df_final_val, df_final_val.check_relevant)\n",
    "df_ngram_grid_dimr_tfidf = gridSearch_to_df(grid_ngram_features_dimr_tfidfonly)\n",
    "df_ngram_grid_dimr_tfidf.to_pickle('grid_ngram_features.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
