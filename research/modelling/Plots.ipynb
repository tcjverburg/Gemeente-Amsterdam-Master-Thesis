{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import sys\n",
    "import re\n",
    "import itertools\n",
    "import operator\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from matplotlib import rc,rcParams\n",
    "\n",
    "from gensim.sklearn_api import D2VTransformer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest, chi2\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, ParameterGrid, cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "base = os.getcwd().split('Master-Thesis')[0].replace('\\\\', '/')\n",
    "sys.path.insert(0, 'C:/Users/tom_v/Documents/Master/Thesis/Master-Thesis/research/pre-processing')\n",
    "\n",
    "from pre_processing_functions import *\n",
    "from model_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths for final datset\n",
    "path_dataset = base + '/Master-Thesis/research/pre-processing/final_dataset.pickle'\n",
    "path_q4_results = 'q4.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading and defining data\n",
    "df_final= pd.read_pickle(path_dataset)\n",
    "\n",
    "#80/20 split train validation\n",
    "df_final_validation = df_final[:int(0.8*len(df_final))] \n",
    "df_test = df_final[int(0.8*len(df_final)):]             \n",
    "labels_test = df_test.check_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read results from RQ4\n",
    "q4 = pd.read_pickle(path_q4_results)\n",
    "plt.rc('text', usetex=True)  \n",
    "plt.rc('font', family='serif') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots for RQ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for RQ4 in the paper for different document types\n",
    "sns.set(style=\"whitegrid\",font_scale=1.9)\n",
    "g = sns.catplot(x=\"Type\", y=\"precision\", hue=\"Vectorization Method\", data=q4,\n",
    "                height=6, kind=\"bar\", palette=\"muted\")\n",
    "g.despine(left=True)\n",
    "\n",
    "plt.yticks(fontsize=25)\n",
    "plt.xticks(fontsize=25)\n",
    "\n",
    "g.set_ylabels(\"Precision\", fontsize = 30)\n",
    "g.set_xlabels(\"Type\", fontsize = 27)\n",
    "g.savefig(\"q4_precision.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots for Chi2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots the word features with the highest scores for the TFIDF vectorization method\n",
    "vectorizer = TfidfVectorizer()\n",
    "df_uitgifte = df_final[(df_final.levering != 1)& (df_final.splitsing != 1)& (df_final.uitgifte == 1)]\n",
    "\n",
    "X_train_features = vectorizer.fit_transform(df_uitgifte.text_tokenized_joined)\n",
    "y_train_labels = df_uitgifte.check_relevant\n",
    "\n",
    "ch2 = SelectKBest(chi2, k = 20)\n",
    "X_train_features = ch2.fit_transform(X_train_features, y_train_labels)\n",
    "top_ranked_scores = [x[1]  for x in sorted(enumerate(ch2.scores_),key=lambda x:x[1], reverse=True)[:20]]\n",
    "top_ranked_terms = list(np.asarray(vectorizer.get_feature_names())[ch2.get_support()])\n",
    "\n",
    "labels = top_ranked_terms\n",
    "values = top_ranked_scores\n",
    "indexes = np.arange(len(labels))\n",
    "\n",
    "width = 0.5\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels, rotation='vertical')\n",
    "\n",
    "plt.xlabel('Term', fontsize=40)\n",
    "plt.ylabel(u\"$\\chi^2$ Score\", fontsize=40)\n",
    "plt.yticks(fontsize=30)\n",
    "plt.xticks(fontsize=35, rotation =45, ha = 'right')\n",
    "plt.savefig('q4_uitgifte_chi.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA plots for final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eda distribution plots for the processed dataset for different labels. \n",
    "\n",
    "df_check_true = df_final[df_final['check_relevant']==True]\n",
    "df_check_false = df_final[df_final['check_relevant']==False]\n",
    "\n",
    "sns.set(style=\"whitegrid\",font_scale=1.9)\n",
    "\n",
    "#In this case, the page feature is plotted. However, unique words can also be plotted instead\n",
    "number_of_pages = sorted(np.array(df_check_true.page))\n",
    "number_of_pagest = sorted(np.array(df_check_false.page))\n",
    "sns.distplot(number_of_pagest, label = 'FALSE')\n",
    "sns.distplot(number_of_pages, label  = 'TRUE')\n",
    "\n",
    "plt.ylabel('Density', fontsize = 25)\n",
    "plt.xlabel('Page Number',fontsize = 22, y = -2)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlim(0, 150)\n",
    "plt.legend(loc='upper right',fontsize = 15)\n",
    "plt.savefig('eda_page.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
