{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import sys\n",
    "import re\n",
    "import itertools\n",
    "import operator\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from matplotlib import rc,rcParams\n",
    "\n",
    "from gensim.sklearn_api import D2VTransformer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest, chi2\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, ParameterGrid, cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "base = os.getcwd().split('Master-Thesis')[0].replace('\\\\', '/')\n",
    "sys.path.insert(0, base + '/Master-Thesis/research/pre-processing')\n",
    "\n",
    "from pre_processing_functions import *\n",
    "from model_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths for final datset\n",
    "path_dataset = base + '/Master-Thesis/research/pre-processing/final_dataset.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading and defining data\n",
    "df_final= pd.read_pickle(path_dataset)\n",
    "\n",
    "#80/20 split train validation\n",
    "df_final_validation = df_final[:int(0.8*len(df_final))] \n",
    "df_test = df_final[int(0.8*len(df_final)):]             \n",
    "labels_test = df_test.check_relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ3 Different vectorization methods with categorical and numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "k_value = 2500\n",
    "C_value = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline\n",
    "model_pipeline_tfidf = Pipeline(steps=[\n",
    "  (\"features\", FeatureUnion([\n",
    "    (\"numerical_features\", ColumnTransformer([(\"numerical\",Pipeline(steps=[\n",
    "                        (\"impute_stage\", SimpleImputer(missing_values=np.nan, strategy=\"median\",)),\n",
    "                        ('scaler', StandardScaler())]),\n",
    "                        [\"page\", 'unique_words'])])), \n",
    "      \n",
    "    (\"categorical_features\", ColumnTransformer([(\"type\",Pipeline(steps=[\n",
    "                        ('imputer', SimpleImputer(strategy='constant', missing_values=np.nan)),\n",
    "                        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))]),\n",
    "                        [\"uitgifte\", 'splitsing','levering', 'year']),])),\n",
    "      \n",
    "      (\"text_features\",ColumnTransformer([(\"title_vec\",Pipeline(steps=[\n",
    "          (\"tfidf\", TfidfVectorizer()),\n",
    "          ('dimred', SelectKBest(chi2, k=k_value))\n",
    "      ]),\"text_tokenized_joined\")]))])),\n",
    " \n",
    "    \n",
    "  (\"classifiers\", LogisticRegression(C=C_value))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit and predict\n",
    "model_pipeline_tfidf.fit(df_final_validation, df_final_validation.check_relevant)\n",
    "prediction = model_pipeline_tfidf.predict(df_test)\n",
    "f1 = f1_score(labels_test, prediction, pos_label=True)\n",
    "recall = recall_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "precision = precision_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "pd.DataFrame([prediction]).to_csv('predictiontfidf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "k_value = 2500\n",
    "C_value = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline\n",
    "model_pipeline_ngram_f_dimred = Pipeline(steps=[\n",
    "  (\"features\", FeatureUnion([\n",
    "    (\"numerical_features\", ColumnTransformer([(\"numerical\",Pipeline(steps=[\n",
    "                        (\"impute_stage\", SimpleImputer(missing_values=np.nan, strategy=\"median\",)),\n",
    "                        ('scaler', StandardScaler())]),\n",
    "                        [\"page\", 'unique_words'])])), \n",
    "      \n",
    "    (\"categorical_features\", ColumnTransformer([(\"type\",Pipeline(steps=[\n",
    "                        ('imputer', SimpleImputer(strategy='constant', missing_values=np.nan)),\n",
    "                        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))]),\n",
    "                        [\"uitgifte\", 'splitsing','levering', 'year']),])),\n",
    "    \n",
    "      (\"text_features\",ColumnTransformer([(\"title_vec\",Pipeline(steps=[\n",
    "          ('tfidf', TfidfVectorizer(ngram_range = (3,3), analyzer = 'char')),\n",
    "          (\"dimred\", SelectKBest(chi2, k=k_value))])                                          \n",
    "        ,\"text_ngrams\")]))])),\n",
    "    \n",
    "  (\"classifiers\", LogisticRegression(C=C_value))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit and predict\n",
    "model_pipeline_ngram_f_dimred.fit(df_final_validation, df_final_validation.check_relevant)\n",
    "prediction = model_pipeline_ngram_f_dimred.predict(df_test)\n",
    "f1 = f1_score(labels_test, prediction, pos_label=True)\n",
    "recall = recall_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "precision = precision_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "pd.DataFrame([prediction]).to_csv('predictionngram.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "sample_value = .13\n",
    "C_value = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline\n",
    "model_pipeline_d2v_features = Pipeline(steps=[\n",
    "  (\"features\", FeatureUnion([\n",
    "    (\"numerical_features\", ColumnTransformer([(\"numerical\",Pipeline(steps=[\n",
    "                        (\"impute_stage\", SimpleImputer(missing_values=np.nan, strategy=\"median\",)),\n",
    "                        ('scaler', StandardScaler())]),\n",
    "                        [\"page\", 'unique_words'])])), \n",
    "      \n",
    "    (\"categorical_features\", ColumnTransformer([(\"type\",Pipeline(steps=[\n",
    "                        ('imputer', SimpleImputer(strategy='constant', missing_values=np.nan)),\n",
    "                        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))]),\n",
    "                        [\"uitgifte\", 'splitsing','levering', 'year']),])),\n",
    "    \n",
    "    (\"text_features\", Pipeline(steps=[\n",
    "        (\"doc2vec\", Doc2VecTransformer(sample = .sample_value)),]),)])),\n",
    "        \n",
    "  (\"classifiers\", LogisticRegression(C=C_value))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit and predict\n",
    "model_pipeline_d2v_features.fit(df_final_validation, df_final_validation.check_relevant)\n",
    "prediction = model_pipeline_d2v_features.predict(df_test)\n",
    "f1 = f1_score(labels_test, prediction, pos_label=True)\n",
    "recall = recall_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "precision = precision_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "pd.DataFrame([prediction]).to_csv('predictiond2v.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 Performance accross different document types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dict to store the different performances for plotting\n",
    "dict_compare = {'precision':[], 'recall':[], 'f1':[], 'Vectorization Method':[], 'Type':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uitgifte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uitgifte df\n",
    "df_test_uitgifte = df_test[(df_test.levering != 1)& (df_test.splitsing != 1)& (df_test.uitgifte == 1)]\n",
    "labels_test = df_test_uitgifte.check_relevant\n",
    "doc_type = 'uitgifte'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_pipeline_tfidf.predict(df_test_uitgifte)\n",
    "f1 = f1_score(labels_test, prediction, pos_label=True)\n",
    "recall = recall_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "precision = precision_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "\n",
    "dict_compare['precision'].append(precision)\n",
    "dict_compare['recall'].append(recall)\n",
    "dict_compare['f1'].append(f1)\n",
    "dict_compare['Type'].append(doc_type)\n",
    "dict_compare['Vectorization Method'].append('TF-IDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_pipeline_ngram_f_dimred.predict(df_test_uitgifte)\n",
    "f1 = f1_score(labels_test, prediction, pos_label=True)\n",
    "recall = recall_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "precision = precision_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "\n",
    "dict_compare['precision'].append(precision)\n",
    "dict_compare['recall'].append(recall)\n",
    "dict_compare['f1'].append(f1)\n",
    "dict_compare['Type'].append(doc_type)\n",
    "dict_compare['Vectorization Method'].append('TRIGRAM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_pipeline_d2v_features.predict(df_test_uitgifte)\n",
    "f1 = f1_score(labels_test, prediction, pos_label=True)\n",
    "recall = recall_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "precision = precision_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "\n",
    "dict_compare['precision'].append(precision)\n",
    "dict_compare['recall'].append(recall)\n",
    "dict_compare['f1'].append(f1)\n",
    "dict_compare['Type'].append(doc_type)\n",
    "dict_compare['Vectorization Method'].append('DBOW')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitsing df\n",
    "df_test_splitsing = df_test[(df_test.levering != 1)& (df_test.splitsing == 1)& (df_test.uitgifte != 1)]\n",
    "labels_test = df_test_splitsing.check_relevant\n",
    "doc_type = 'splitsing'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_pipeline_tfidf.predict(df_test_splitsing)\n",
    "f1 = f1_score(labels_test, prediction, pos_label=True)\n",
    "recall = recall_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "precision = precision_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "\n",
    "dict_compare['precision'].append(precision)\n",
    "dict_compare['recall'].append(recall)\n",
    "dict_compare['f1'].append(f1)\n",
    "dict_compare['Type'].append(doc_type)\n",
    "dict_compare['Vectorization Method'].append('TF-IDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_pipeline_ngram_f_dimred.predict(df_test_splitsing)\n",
    "f1 = f1_score(labels_test, prediction, pos_label=True)\n",
    "recall = recall_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "precision = precision_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "\n",
    "dict_compare['precision'].append(precision)\n",
    "dict_compare['recall'].append(recall)\n",
    "dict_compare['f1'].append(f1)\n",
    "dict_compare['Type'].append(doc_type)\n",
    "dict_compare['Vectorization Method'].append('TRIGRAM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_pipeline_d2v_features.predict(df_test_splitsing)\n",
    "f1 = f1_score(labels_test, prediction, pos_label=True)\n",
    "recall = recall_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "precision = precision_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "\n",
    "\n",
    "dict_compare['precision'].append(precision)\n",
    "dict_compare['recall'].append(recall)\n",
    "dict_compare['f1'].append(f1)\n",
    "dict_compare['Type'].append(doc_type)\n",
    "dict_compare['Vectorization Method'].append('DBOW')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Levering df\n",
    "df_test_levering = df_test[(df_test.levering == 1)& (df_test.splitsing != 1)& (df_test.uitgifte != 1)]\n",
    "labels_test = df_test_levering.check_relevant\n",
    "doc_type = 'levering'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_pipeline_tfidf.predict(df_test_levering)\n",
    "f1 = f1_score(labels_test, prediction, pos_label=True)\n",
    "recall = recall_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "precision = precision_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "\n",
    "\n",
    "dict_compare['precision'].append(precision)\n",
    "dict_compare['recall'].append(recall)\n",
    "dict_compare['f1'].append(f1)\n",
    "dict_compare['Type'].append(doc_type)\n",
    "dict_compare['Vectorization Method'].append('TF-IDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_pipeline_ngram_f_dimred.predict(df_test_levering)\n",
    "f1 = f1_score(labels_test, prediction, pos_label=True)\n",
    "recall = recall_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "precision = precision_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "\n",
    "dict_compare['precision'].append(precision)\n",
    "dict_compare['recall'].append(recall)\n",
    "dict_compare['f1'].append(f1)\n",
    "dict_compare['Type'].append(doc_type)\n",
    "dict_compare['Vectorization Method'].append('TRIGRAM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_pipeline_d2v_features.predict(df_test_levering)\n",
    "f1 = f1_score(labels_test, prediction, pos_label=True)\n",
    "recall = recall_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "precision = precision_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "\n",
    "dict_compare['precision'].append(precision)\n",
    "dict_compare['recall'].append(recall)\n",
    "dict_compare['f1'].append(f1)\n",
    "dict_compare['Type'].append(doc_type)\n",
    "dict_compare['Vectorization Method'].append('DBOW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4 = pd.DataFrame.from_dict(dict_compare)\n",
    "q4.to_pickle('q4.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
