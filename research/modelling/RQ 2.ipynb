{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import sys\n",
    "import re\n",
    "import itertools\n",
    "import operator\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from matplotlib import rc,rcParams\n",
    "\n",
    "from gensim.sklearn_api import D2VTransformer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest, chi2\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, ParameterGrid, cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "base = os.getcwd().split('Master-Thesis')[0].replace('\\\\', '/')\n",
    "sys.path.insert(0, base + '/Master-Thesis/research/pre-processing')\n",
    "\n",
    "from pre_processing_functions import *\n",
    "from model_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths for final datset\n",
    "path_dataset = base + '/Master-Thesis/research/pre-processing/final_dataset.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading and defining data\n",
    "df_final= pd.read_pickle(path_dataset)\n",
    "\n",
    "#80/20 split train validation\n",
    "df_final_validation = df_final[:int(0.8*len(df_final))] \n",
    "df_test = df_final[int(0.8*len(df_final)):]             \n",
    "labels_test = df_test.check_relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ 2 Different Vectorization Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "k_value = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('dimred', SelectKBest(chi2, k=k_value)),\n",
    "    ('logistic', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe_tfidf.fit(df_final_validation.text_tokenized_joined, df_final_validation.check_relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pipe_tfidf.predict(df_test.text_tokenized_joined)\n",
    "f1 = f1_score(labels_test, prediction, pos_label=True)\n",
    "recall = recall_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "precision = precision_score(labels_test, prediction,  average=\"binary\", pos_label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "k_value = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_grid_ngram = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range = (4,4), analyzer = 'char')), #or Doc2vecTransformer\n",
    "    ('dimred', SelectKBest(chi2, k = k_value)),\n",
    "    ('logistic', LogisticRegression())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe_grid_ngram.fit(df_final_validation.text_ngrams, df_final_validation.check_relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pipe_grid_ngram.predict(df_test.text_ngrams)\n",
    "f1 = f1_score(labels_test, prediction, pos_label=True)\n",
    "recall = recall_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "precision = precision_score(labels_test, prediction,  average=\"binary\", pos_label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "C_value = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piped2v = Pipeline([\n",
    "    ('doc2vec', Doc2VecTransformer(text = 'text_tokenized')), #or Doc2vecTransformer\n",
    "    ('logistic', LogisticRegression(C = C_value))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "piped2v.fit(df_final_validation, df_final_validation.check_relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = piped2v.predict(df_test)\n",
    "f1 = f1_score(labels_test, prediction, pos_label=True)\n",
    "recall = recall_score(labels_test, prediction,  average=\"binary\", pos_label=True)\n",
    "precision = precision_score(labels_test, prediction,  average=\"binary\", pos_label=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
